{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road using Advanced Techniques** \n",
    "### **Adam Tetelman**\n",
    "***\n",
    "In this project I used used various image processing techniques to detect lanes on the road, ensure changes between images are reasonable, and display a final road image.\n",
    "\n",
    "The project relies on the following packages:\n",
    "- python3 (and standard libraries)\n",
    " - numpy (for array manipulation)\n",
    " - cv2 (for image processing - opencv2)  \n",
    " - matplotlib (for debugging/tuning and rendering images)\n",
    " - moviepy (for video rendering)\n",
    " - Jupyter/Ipython (for this notebook)\n",
    "\n",
    "\n",
    "The tools taught included:\n",
    "- Camera Calibration & Distortion\n",
    "- Perspective Transofrm Techniques\n",
    "- Convolutional Lane Detection\n",
    "- Histogram Lane Detection\n",
    "- Sobel Edge Detection Thresholds (x, y, magnitude, direction)\n",
    "- Colorspace Conversion & Thresholding\n",
    "- Lane Curvature Calculation\n",
    "\n",
    "The resources used included:\n",
    "- ./results (result images and videos)\n",
    "- ./camera_cal (camera calibration images)\n",
    "- ./test_img (test images)\n",
    "- ./test_vid (test videos)\n",
    "\n",
    "The code is structured into a `Line` class (lane lines), a `LaneLines` class (lane lines detection), a base `Pipeline` class (base pipeline functionality), a car_helper module (common functionality), a CarWorld class (container for video processing and all pipelines), and  and some test code. \n",
    "\n",
    "The test images can be reproduced by running the lane_lines.py module. The output videos can be reproduced by running the car_world.py module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Pipeline Summary\n",
    "The main project pipeline takes a camera image and runs throught the below steps:\n",
    "\n",
    "- Undistort\n",
    "- Detect Edges\n",
    "- Perspective Transform\n",
    "- Detect Lanes\n",
    "- Fill Lanes\n",
    "- Undo Perspective Transform\n",
    "- Calculate Curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Camera Calibration\n",
    "\n",
    "Before even beginning the pipeline it was necessary to calibrate for camera distortion.\n",
    "\n",
    "This was done using 9x6 chessboards images taken from various angles and built in opencv2 functions to detect chessboard corners and calibrate for distortion.\n",
    "\n",
    "The images used for calibration can be found in ./camera_cal. The calibration data is saved to ./results/calibration_data.p. The code used to generate the calibration is in the calibrate and calibrate_camera functions of the `Pipeline` base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "<tr>\n",
       "  <td><b>Original</b></td>\n",
       "  <td><b>Detected Corners</b></td>\n",
       "  <td><b>Undistorted</b></td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td><img width=\"200px\" src=\"camera_cal/calibration02.jpg\"></td>\n",
       "  <td><img width=\"200px\" src=\"results/corners_found2.jpg\"></td>\n",
       "  <td><img width=\"200px\" src=\"results/undistort2.jpg\"></td>\n",
       "</tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<table>\n",
    "<tr>\n",
    "  <td><b>Original</b></td>\n",
    "  <td><b>Detected Corners</b></td>\n",
    "  <td><b>Undistorted</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td><img width=\"200px\" src=\"camera_cal/calibration02.jpg\"></td>\n",
    "  <td><img width=\"200px\" src=\"results/corners_found2.jpg\"></td>\n",
    "  <td><img width=\"200px\" src=\"results/undistort2.jpg\"></td>\n",
    "</tr>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Undistort\n",
    "\n",
    "This step uses the previously calculated camera calibration data to remove distortion from images. The code is located in `PipeLine.correct_distortion` and is called in `CarWorld.pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "<tr>\n",
       "<td><b>Original</b></td>\n",
       "<td><b>Undistorted</b></td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td><img src=\"results/test-original.jpg\"></td>\n",
       "<td><img src=\"results/test-undistort.jpg\"></td>\n",
       "</tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<table>\n",
    "<tr>\n",
    "<td><b>Original</b></td>\n",
    "<td><b>Undistorted</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"results/test-original.jpg\"></td>\n",
    "<td><img src=\"results/test-undistort.jpg\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Detect Edges\n",
    "\n",
    "The edge detection takes an undistorted image as input, runs through the below gradients, and returns the edge mask. The code is located in `LaneLines.edge_detection` and several `LaneLines.<type>_thresh` functions.\n",
    "\n",
    "- Color threshold\n",
    "  - Convert RGB to HLS\n",
    "  - Saturation threshold\n",
    "- Sobel Y gradient threshold\n",
    "- Sobel X gradient threshold\n",
    "- Location threshold\n",
    "- And of all thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<br><table><b>Thresholding (seperate)</b>\n",
    "<tr>\n",
    "<td><b>Undistorted</b></td>\n",
    "<td><b>Color Threshold</b></td>\n",
    "<td><b>Y Gradient</b></td>\n",
    "<td><b>X Gradient</b></td>\n",
    "<td><b>Location Threshold</b></td>\n",
    "<td><b>Edge Detection</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"results/test-undistort.jpg\"></td>\n",
    "<td><img src=\"results/color_edge.jpg\"></td>\n",
    "<td><img src=\"results/y_edge.jpg\"></td>\n",
    "<td><img src=\"results/x_edge.jpg\"></td>\n",
    "<td><img src=\"results/loc_thresh.jpg\"></td>\n",
    "<td><img src=\"results/edge.jpg\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Perspective Transform\n",
    "\n",
    "In order to transform a front facing image into a top-down image I had to tune the polygon values stored in `LaneLines.trans_src` and `LaneLines.trans_dst`. When a LaneLines is initialized the `LaneLines.setup_transform` function is called which calculates and save the transformation (`trans_M`) and reverse transformation matrix (`trans_M_rev`).\n",
    "\n",
    "The `LaneLines.perspective_transform` takes an image and switches the viewpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<br><table> Curved Image\n",
    "<tr>\n",
    "<td><b>Undistorted</b></td>\n",
    "<td><b>Transformed (Edge image)</b></td>\n",
    "<td><b>Transformed (Undistorted image)</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"results/test-undistort.jpg\"></td>\n",
    "<td><img src=\"results/transform.jpg\"></td>\n",
    "<td><img src=\"results/undistort_transform.jpg\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<br><table> Straight Image\n",
    "<tr>\n",
    "<td><b>Undistorted</b></td>\n",
    "<td><b>Transformed (Edge image)</b></td>\n",
    "<td><b>Transformed (Undistorted image)</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"results/test-straight.jpg\"></td>\n",
    "<td><img src=\"results/transform_straight.jpg\"></td>\n",
    "<td><img src=\"results/undistort_transform_straight.jpg\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Detect Lanes\n",
    "I used a convolutional technique to identify lane lines. In my `LaneLines.find_lanes_conv` function I define a convolution size and the number of layers to break the image into. I then go (horizontal) layer by layer and run convolutions across each. I do this for the right and left half of the image. The result is a `level` centroids for the left and right lane. I then save these values to the left and right `Line`, call some class functions to calculate a line of best fit/save the points/etc. Future calls to the `find_lanes_conv` function will result in re-use of previously detected centroid points.\n",
    "\n",
    "Because this is a single test image, the fit may not be the best. In the video output, previous points are taken into account when fitting which results in a more robust lane that is less affected by noise/missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<br><table>\n",
    "<tr>\n",
    "<td><b>Transformed (Edge image)</b></td>\n",
    "<td><b>Lanes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"results/transform.jpg\"></td>\n",
    "<td><img src=\"results/lanes_lines.jpg\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fill Lanes\n",
    "After detecting the lanes we have a left and right line corresponding to them. In `LaneLines.fill_lanes` I use the fillPoly function to fill better display the lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<br><table>\n",
    "<tr>\n",
    "<td><b>Transformed (Edge image)</b></td>\n",
    "<td><b>Lanes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"results/transform.jpg\"></td>\n",
    "<td><img src=\"results/lanes_filled.jpg\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Undo Transform\n",
    "In this step we simple run the image through the `perspective_transform` function with `rev=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<br><table>\n",
    "<tr>\n",
    "<td><b>Lanes Image</b></td>\n",
    "<td><b>Un-Transformed</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"results/lanes_filled.jpg\"></td>\n",
    "<td><img src=\"results/transform_lanes.jpg\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Calculate Curvature & Detect Car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This functionality lives in the `LaneLines.calculate_curvature` and `Lines.update_curve` functions.\n",
    "\n",
    "I convert the (x, y) coordinate points to reflect meters instead of pixels, use numpy to calculate the line of best fit polynomials, then use those polynomials to calculate the curve.\n",
    "\n",
    "I calculate the position of the car in `LaneLines.calculate_car` using the bottommost position of the left/right lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<br><table>\n",
    "<tr>\n",
    "<td><b>Final output</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"results/pipeline.jpg\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Video results\n",
    "\n",
    "Along with the final output, I have included a debug video that contains the output from each stage in the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"results/project_video_output.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"results/project_video_output_debug.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The most difficult part of this project was adding robustness to the lane detection. I had some troubles with this at first. At first I was using a histogram to detect lane lines, however after switching to the convolutional method I saw much better results. In combination with some re-use of data and some sanity checks I was able to get this working. Overall, there was a lot of give-and-take between the pieces in the pipeline. Having a more open edge detection required different types of line detection than edge detection that was very particular. The solutions I came up with could be completely wrong for someone using a different edge detection system.\n",
    "\n",
    "Possible problem areas:\n",
    "- Videos of cars changing lanes\n",
    "- Very dark roads\n",
    "- Very curvy roads\n",
    "\n",
    "Future Improvements:\n",
    "- More complex outlier detection \n",
    "- More sanity checks between lines and past data\n",
    "- Testing with additional video data\n",
    "- Lane detection using multiple techniques\n",
    "\n",
    "Final Thoughts:\n",
    "\n",
    "Each step in this process was fairly simple. Edge detection, masking, curvature calculations, and lane detection. Put them all together and you have a fairly robust system to detect where the car and lanes are on the road. This program is able to accomplish a complex task in only 600 lines of code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdc35",
   "language": "python",
   "name": "sdc35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
